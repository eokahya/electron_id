{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.3\n",
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "## Import libraries\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from   matplotlib import pylab\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(697)\n",
    "\n",
    "from sklearn            import preprocessing\n",
    "from sklearn            import metrics\n",
    "from sklearn.metrics    import confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.datasets   import make_classification\n",
    "from sklearn.neighbors  import KNeighborsClassifier\n",
    "from sklearn.ensemble   import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ''\n",
    "#if torch.cuda.is_available():   \n",
    "#    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#def to_numpy(tensor):\n",
    "#    '''converts a GPU tensor to a numpy array'''\n",
    "#    return tensor.cpu().detach().numpy()\n",
    "\n",
    "# Bunu bu aşamada yapmıyoruz. Sebebi data'yı cpu'da oluşturup sonra batch batch to.device ile gpu'ya aktaracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m Key name:\u001b[1;m ['em_barrel_Lr0', 'em_barrel_Lr1', 'em_barrel_Lr1_fine', 'em_barrel_Lr2', 'em_barrel_Lr3', 'eventNumber', 'mcChannelNumber', 'p_ECIDSResult', 'p_Eratio', 'p_LHLoose', 'p_LHMedium', 'p_LHTight', 'p_LHValue', 'p_Reta', 'p_Rhad', 'p_Rphi', 'p_TRTPID', 'p_TruthOrigin', 'p_TruthType', 'p_charge', 'p_chi2', 'p_d0', 'p_d0Sig', 'p_dPOverP', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_e', 'p_et_calo', 'p_eta', 'p_f1', 'p_f3', 'p_firstEgMotherTruthOrigin', 'p_firstEgMotherTruthType', 'p_iffTruth', 'p_mean_charge', 'p_mean_chi2', 'p_mean_d0', 'p_mean_deta', 'p_mean_dphi', 'p_mean_efrac', 'p_mean_ndof', 'p_mean_pixhits', 'p_mean_scthits', 'p_mean_sigmad0', 'p_mean_trthits', 'p_mean_vertex', 'p_mean_z0', 'p_nTracks', 'p_ndof', 'p_numberOfSCTHits', 'p_phi', 'p_pt_track', 'p_qd0Sig', 'p_sct_weight_charge', 'p_sigmad0', 'p_tracks', 'p_truth_eta', 'p_truth_phi', 'p_truth_pt', 'p_weta2', 'tile_barrel_Lr1', 'tile_barrel_Lr2', 'tile_barrel_Lr3', 'tracks', 'true_m']\n"
     ]
    }
   ],
   "source": [
    "f = h5.File('./el_data.h5', 'r') ## gives group\n",
    "print('\\033[1;35m Key name:\\033[1;m', list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['em_barrel_Lr0', 'em_barrel_Lr1', 'em_barrel_Lr1_fine', 'em_barrel_Lr2', 'em_barrel_Lr3', 'eventNumber', 'mcChannelNumber', 'p_ECIDSResult', 'p_Eratio', 'p_LHLoose', 'p_LHMedium', 'p_LHTight', 'p_LHValue', 'p_Reta', 'p_Rhad', 'p_Rphi', 'p_TRTPID', 'p_TruthOrigin', 'p_TruthType', 'p_charge', 'p_chi2', 'p_d0', 'p_d0Sig', 'p_dPOverP', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_e', 'p_et_calo', 'p_eta', 'p_f1', 'p_f3', 'p_firstEgMotherTruthOrigin', 'p_firstEgMotherTruthType', 'p_iffTruth', 'p_mean_charge', 'p_mean_chi2', 'p_mean_d0', 'p_mean_deta', 'p_mean_dphi', 'p_mean_efrac', 'p_mean_ndof', 'p_mean_pixhits', 'p_mean_scthits', 'p_mean_sigmad0', 'p_mean_trthits', 'p_mean_vertex', 'p_mean_z0', 'p_nTracks', 'p_ndof', 'p_numberOfSCTHits', 'p_phi', 'p_pt_track', 'p_qd0Sig', 'p_sct_weight_charge', 'p_sigmad0', 'p_tracks', 'p_truth_eta', 'p_truth_phi', 'p_truth_pt', 'p_weta2', 'tile_barrel_Lr1', 'tile_barrel_Lr2', 'tile_barrel_Lr3', 'tracks', 'true_m']\n"
     ]
    }
   ],
   "source": [
    "file_name = h5.File('./el_data.h5', 'r') ## gives group\n",
    "keys = list(file_name.keys())\n",
    "print(keys)\n",
    "#print(list(file_name[keys[0]]))\n",
    "#print(list(file_name[keys[1]]))\n",
    "#print(list(file_name[list(file_name.keys())[0]])) ## or\n",
    "file_name.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_datasets(hdf_file):\n",
    "\n",
    "    def h5_dataset_iterator(g, prefix=''):\n",
    "        for key in g.keys():\n",
    "            item = g[key]\n",
    "            path = f'{prefix}/{key}'\n",
    "            if isinstance(item, h5.Dataset): ## test for dataset\n",
    "                yield (path, item)\n",
    "            elif isinstance(item, h5.Group): ## test for group (go down)\n",
    "                yield from h5_dataset_iterator(item, path)\n",
    "\n",
    "    with h5.File(hdf_file, 'r') as f:\n",
    "        for path, _ in h5_dataset_iterator(f):\n",
    "            yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr0\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr1\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr1_fine\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 56, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr2\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr3\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /eventNumber\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /mcChannelNumber\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_ECIDSResult\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Eratio\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHLoose\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHMedium\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHTight\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHValue\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Reta\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Rhad\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Rphi\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_TRTPID\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_TruthOrigin\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_TruthType\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_charge\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_chi2\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_d0\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_d0Sig\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_dPOverP\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_deltaEta1\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_deltaPhiRescaled2\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_e\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_et_calo\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_eta\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_f1\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_f3\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_firstEgMotherTruthOrigin\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_firstEgMotherTruthType\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_iffTruth\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_charge\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_chi2\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_d0\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_deta\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_dphi\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_efrac\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_ndof\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_pixhits\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_scthits\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_sigmad0\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_trthits\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_vertex\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_z0\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_nTracks\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_ndof\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_numberOfSCTHits\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_phi\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_pt_track\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_qd0Sig\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_sct_weight_charge\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_sigmad0\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_tracks\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 20, 13)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_truth_eta\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_truth_phi\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_truth_pt\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_weta2\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tile_barrel_Lr1\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tile_barrel_Lr2\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tile_barrel_Lr3\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tracks\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640, 50, 5)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /true_m\n",
      "\u001b[1;36m Shape:\u001b[1;m (14675640,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with h5.File('./el_data.h5', 'r') as f:\n",
    "    for dset in traverse_datasets('./el_data.h5'):\n",
    "        \n",
    "        print('\\033[1;35m Path:\\033[1;m', dset)\n",
    "        \n",
    "        print('\\033[1;36m Shape:\\033[1;m', f[dset].shape)\n",
    "        \n",
    "        print('\\033[1;33m Data type:\\033[1;m', f[dset].dtype)\n",
    "        \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(data_file, batch_size, all_features, images, upscale=False, denormalize=False, index=0):\n",
    "    data = h5.File(data_file, 'r')\n",
    "    idx_1, idx_2 = index*batch_size, (index+1)*batch_size\n",
    "    sample_dict  = dict([key, data[key][idx_1:idx_2]] for key in all_features)\n",
    "    if images != [] and denormalize:\n",
    "        energy = sample_dict['p_e']\n",
    "        for key in images: sample_dict[key] = sample_dict[key] * energy[:, np.newaxis, np.newaxis]\n",
    "        sample_dict['tracks'][:,:,0] = sample_dict['tracks'][:,:,0] * energy[:, np.newaxis]\n",
    "    if images != [] and upscale:\n",
    "        for i in images: sample_dict[i] = resize_images(np.float32(sample_dict[i]), target_shape=(56,11))\n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images    = ['em_barrel_Lr0',  'em_barrel_Lr1', 'em_barrel_Lr2', 'em_barrel_Lr3',\n",
    "             'tile_barrel_Lr1', 'tile_barrel_Lr2', 'tile_barrel_Lr3']\n",
    "#images    = ['em_barrel_Lr1_fine']\n",
    "tracks    = ['tracks' ]\n",
    "scalars   = ['p_Eratio', 'p_Reta', 'p_Rhad', 'p_Rphi', 'p_TRTPID', 'p_d0', 'p_d0Sig', 'p_dPOverP',\n",
    "             'p_deltaPhiRescaled2', 'p_deltaEta1', 'p_f1', 'p_f3', 'p_numberOfSCTHits', 'p_weta2']\n",
    "others    = ['p_TruthType', 'p_iffTruth', 'p_LHTight', 'p_LHMedium', 'p_LHLoose', 'p_e']\n",
    "#train_features = {'images':images, 'tracks':tracks, 'scalars':scalars}\n",
    "train_features = {'images':images, 'tracks':[], 'scalars':[]}\n",
    "all_features   = np.sum(list(train_features.values())) + others\n",
    "if train_features['images'] == []: args.n_type = 'FCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34089730048"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(device=None).total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './el_data2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_e = 1000000\n",
    "n_e = 14675640\n",
    "xtrain_data = make_sample(data_file, n_e, all_features, train_features['images'], upscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [ np.expand_dims(np.float32(xtrain_data[key]),axis = 1)  for key in np.sum(list(train_features.values()))]\n",
    "#train_data = [np.float32(train_data[key])[:,np.newaxis,:,:]  for key in np.sum(list(train_features.values()))]\n",
    "#train_data = [np.float32(train_data[key]) for key in np.sum(list(train_features.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14675640, 1, 7, 11)\n",
      "(14675640, 1, 7, 11)\n",
      "(14675640, 1, 7, 11)\n",
      "(14675640, 1, 7, 11)\n",
      "(14675640, 1, 7, 11)\n",
      "(14675640, 1, 7, 11)\n",
      "(14675640, 1, 7, 11)\n"
     ]
    }
   ],
   "source": [
    "for element in train_data:\n",
    "    print(element.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14675640, 7, 7, 11)\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate(train_data, axis=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(data, n_classes):\n",
    "    if   n_classes == 2:\n",
    "        labels = np.where(np.logical_or(data['p_TruthType']==2, data['p_TruthType']==4), 0, 1)\n",
    "    elif n_classes == 5:\n",
    "        truth  = data['p_iffTruth']\n",
    "        labels = np.where(truth==2, 0, 4     )\n",
    "        labels = np.where(truth==3, 1, labels)\n",
    "        labels = np.where(np.logical_or (truth==1, truth==10), 2, labels)\n",
    "        labels = np.where(np.logical_and(truth>=7, truth<= 9), 3, labels)\n",
    "    elif n_classes == 9:\n",
    "        labels = data['p_iffTruth']\n",
    "        labels = np.where(labels== 9, 4, labels)\n",
    "        labels = np.where(labels==10, 6, labels)\n",
    "    else:\n",
    "        print('\\nCLASSIFIER:', n_classes, 'classes not supported -> exiting program\\n')\n",
    "        sys.exit()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14675640,)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "y = make_labels(xtrain_data, n_classes)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xtrain_data\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds, val_ds = random_split(x, [90000, 10000])\n",
    "#len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x -= np.mean(x, axis=0)\n",
    "x /= np.std(x, axis=0)\n",
    "shuffle_idx = np.random.permutation(x.shape[0])\n",
    "x = x[shuffle_idx]\n",
    "y = y[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x /= 0.0052  bu 56 x 11 imageler için geçerli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.9\n",
    "idx = int(train_frac * len(x))\n",
    "x_train, x_test = x[:idx], x[idx:]\n",
    "y_train, y_test = y[:idx], y[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "#num_epochs=20\n",
    "num_epochs=10\n",
    "#num_classes=10\n",
    "nw=1\n",
    "bs1=5000\n",
    "bs2=5000\n",
    "#bs=64\n",
    "wd=1e-5\n",
    "lr=1e-5\n",
    "momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_x = torch.stack([torch.Tensor(i) for i in x_train])\n",
    "train_tensor_y = torch.stack([torch.zeros([1])+i for i in y_train])\n",
    "train_tensor_y = train_tensor_y.type(torch.long).squeeze(1)\n",
    "#train_tensor_ycpu = train_tensor_y.to('cpu')\n",
    "#train_tensor_xcpu = train_tensor_x.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m tensor_x type: \u001b[1;m torch.FloatTensor\n",
      "\u001b[1;35m tensor_x dtype: \u001b[1;m torch.float32\n",
      "\u001b[1;36m tensor_x num of dims: \u001b[1;m 4\n",
      "\u001b[1;34m tensor_x Shape:\u001b[1;m torch.Size([13208076, 7, 7, 11])\n",
      "\u001b[1;33m tensor_y type: \u001b[1;m torch.LongTensor\n",
      "\u001b[1;35m tensor_y dtype: \u001b[1;m torch.int64\n",
      "\u001b[1;36m tensor_y num of dims: \u001b[1;m 1\n",
      "\u001b[1;34m tensor_y Shape:\u001b[1;m torch.Size([13208076])\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;33m tensor_x type: \\033[1;m', train_tensor_x.type())\n",
    "print('\\033[1;35m tensor_x dtype: \\033[1;m', train_tensor_x.dtype)\n",
    "print('\\033[1;36m tensor_x num of dims: \\033[1;m', train_tensor_x.dim())\n",
    "print('\\033[1;34m tensor_x Shape:\\033[1;m', train_tensor_x.shape)\n",
    "print('\\033[1;33m tensor_y type: \\033[1;m', train_tensor_y.type())\n",
    "print('\\033[1;35m tensor_y dtype: \\033[1;m', train_tensor_y.dtype)\n",
    "print('\\033[1;36m tensor_y num of dims: \\033[1;m', train_tensor_y.dim())\n",
    "print('\\033[1;34m tensor_y Shape:\\033[1;m', train_tensor_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor_x = torch.stack([torch.Tensor(i) for i in x_test])\n",
    "test_tensor_y = torch.stack([torch.zeros([1])+i for i in y_test])\n",
    "test_tensor_y = test_tensor_y.type(torch.long).squeeze(1)\n",
    "#test_tensor_ycpu = test_tensor_y.to('cpu')\n",
    "#test_tensor_xcpu = test_tensor_x.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_test\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m tensor_x type: \u001b[1;m torch.FloatTensor\n",
      "\u001b[1;35m tensor_x dtype: \u001b[1;m torch.float32\n",
      "\u001b[1;36m tensor_x num of dims: \u001b[1;m 4\n",
      "\u001b[1;34m tensor_x Shape:\u001b[1;m torch.Size([1467564, 7, 7, 11])\n",
      "\u001b[1;33m tensor_x type: \u001b[1;m torch.LongTensor\n",
      "\u001b[1;35m tensor_x dtype: \u001b[1;m torch.int64\n",
      "\u001b[1;36m tensor_x num of dims: \u001b[1;m 1\n",
      "\u001b[1;34m tensor_x Shape:\u001b[1;m torch.Size([1467564])\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;33m tensor_x type: \\033[1;m', test_tensor_x.type())\n",
    "print('\\033[1;35m tensor_x dtype: \\033[1;m', test_tensor_x.dtype)\n",
    "print('\\033[1;36m tensor_x num of dims: \\033[1;m', test_tensor_x.dim())\n",
    "print('\\033[1;34m tensor_x Shape:\\033[1;m', test_tensor_x.shape)\n",
    "print('\\033[1;33m tensor_x type: \\033[1;m', test_tensor_y.type())\n",
    "print('\\033[1;35m tensor_x dtype: \\033[1;m', test_tensor_y.dtype)\n",
    "print('\\033[1;36m tensor_x num of dims: \\033[1;m', test_tensor_y.dim())\n",
    "print('\\033[1;34m tensor_x Shape:\\033[1;m', test_tensor_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "val_transformer = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_x.transform=train_transformer\n",
    "test_tensor_x.transform=val_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_transformer = transforms.Compose(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#       std=[0.229, 0.224, 0.225]))\n",
    "#val_transformer = transforms.Compose([transforms.ToTensor()]transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                  std=[0.229, 0.224, 0.225]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_tensor_x, train_tensor_y) \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs1, num_workers=nw, shuffle=True) \n",
    "valid_dataset = torch.utils.data.TensorDataset(test_tensor_x, test_tensor_y) \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=bs2, num_workers=nw, shuffle=False) \n",
    "\n",
    "#Burda shuffle true false vs gibi seçenekleri de alabiliriz\n",
    "#Number of workers'ı 1'den farklı alınca sorun çıkıyor çözemedim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0014), tensor(1.0105))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_tensor_x), num_workers=1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "valid_loader = DeviceDataLoader(valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device: cuda:0\n",
      "yb: tensor([1, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "torch.Size([1467, 7, 7, 11])\n",
      "torch.Size([1467])\n"
     ]
    }
   ],
   "source": [
    "#for xb, yb in valid_loader:\n",
    "#    print('xb.device:', xb.device)\n",
    "#    print('yb:', yb)\n",
    "#    print(xb.shape)\n",
    "#    print(yb.shape)    \n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, valid_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in valid_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, valid_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, valid_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(7, 32, kernel_size=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(1), \n",
    "            nn.Linear(13*17*16, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(7, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(32, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Flatten()\n",
       "    (13): Linear(in_features=3536, out_features=100, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CnnModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6929271817207336, 'val_acc': 0.6295889019966125}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.2017, val_loss: 0.1862, val_acc: 0.9375\n",
      "Epoch [1], train_loss: 0.1851, val_loss: 0.1831, val_acc: 0.9387\n",
      "Epoch [2], train_loss: 0.1819, val_loss: 0.1791, val_acc: 0.9400\n",
      "Epoch [3], train_loss: 0.1792, val_loss: 0.1783, val_acc: 0.9406\n",
      "Epoch [4], train_loss: 0.1778, val_loss: 0.1772, val_acc: 0.9408\n",
      "Epoch [5], train_loss: 0.1767, val_loss: 0.1769, val_acc: 0.9412\n",
      "Epoch [6], train_loss: 0.1759, val_loss: 0.1761, val_acc: 0.9414\n",
      "Epoch [7], train_loss: 0.1752, val_loss: 0.1759, val_acc: 0.9416\n",
      "Epoch [8], train_loss: 0.1748, val_loss: 0.1769, val_acc: 0.9409\n",
      "Epoch [9], train_loss: 0.1742, val_loss: 0.1743, val_acc: 0.9419\n"
     ]
    }
   ],
   "source": [
    "history = fit(num_epochs, lr, model, train_loader, valid_loader, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3zO5f/A8dd974ixOe2AoSnGV5LmbLPNaidD+AqRvpFQUSpR5PDVt0gkJYmSHx3m0BzmzBwyRKiwURTGNnIYNjvYPr8/rnZvt83scN+7d3g/H4/7sd2Hz+dzfS6z967T+9JpmqYhhBBCFJLe0gUQQghRvkjgEEIIUSQSOIQQQhSJBA4hhBBFIoFDCCFEkUjgEEIIUSQSOIQo5xYsWECnTp3w8fGxdFEA2L17N71797Z0MYQZSeAQFtG9e3fWrFlj6WKYxLRp02jWrBl79+41vHb58mWaNWtGcnKyWa+dlJTEggULWL9+Pbt37zbrtYTIJoFDCBNwcnLio48+KvXrJiYmUqNGDWrVqlXq1xaVlwQOUaZkZGQwc+ZMfHx86Ny5M5MnT+b27dsAJCcnM3r0aNq3b0+7du3o06eP4b158+bRpUsXvLy8CAwM5Ndff81z7sjIyDxdKEuWLGHEiBEAbNmyhcDAQLy8vPD29ua7774rdLkDAwO5evUq27dvz/f9W7du8dZbb9GpUye6du3KnDlzyMzMLNS5//77b15++WXat29Pt27dWLp0KQAnTpzgueee4++//8bf358pU6bke/yePXt48skn8fLy4qmnniImJsbwXufOnfn000956qmnCA0N5Z133iE9Pd3wfkREBIGBgbRt25Zhw4Zx4cIFw3uJiYm88sordOrUifbt2zNhwgSj686bN4927drRtWtXNm7caHi9JPUsyghNCAsIDQ3VIiIi8rz+2Wefab169dISEhK0a9euaYMGDdLeffddTdM0bfHixdqLL76opaWlaZmZmdqvv/6qpaWlab/99pvm5+enXblyRdM0TTt37pwWHx+f59wpKSla69attT///NPwWu/evbX169drWVlZWps2bbRffvlF0zRNu379unby5MlC3cvUqVO1qVOnaitXrtR69OihZWVlaZcuXdKaNm2q3bp1S9M0TZs4caI2dOhQLSkpSbt48aIWEhKiLVmypFDn/89//qONHz9eu337tnby5Emtc+fO2tatWzVN07QTJ05o3t7e9zz21KlTmpeXl3bgwAEtMzNTi4yM1Hx9fbXU1FRN0zStU6dO2rBhw7SMjAwtIyNDe/7557VPP/1U0zRN+/nnnzUvLy/t6NGjWlpamvb+++9rTz75pJaVlaVlZmZqvXv31iZPnqzdvHlTS0tL0w4ePKhpmqbt2rVLa9GihfbFF19oaWlp2rZt27THHntMu337donqWZQd0uIQZcq6desYOXIkLi4uODk5MWbMGMNYiLW1NVeuXOHMmTPo9XoefvhhbG1tsba25vbt28TGxpKeno67uzuurq55zl2lShW6devG+vXrAfjrr784c+YM/v7+hvPHxsZy8+ZNHB0dadq0aZHK3qtXL1JTU43+us62fv16Xn31VWrUqIGbmxvDhw8v1BjP1atX2bt3L+PGjcPe3p6mTZsycOBA1q5dW6gyrVixgu7du9OuXTv0ej0hISHUrFmTo0ePGj4zaNAgrK2tsba2ZvDgwURGRgLq36Jnz5488sgj2Nra8sorr/Dnn3/y+++/Exsby9mzZ3nrrbdwcHDA1tYWLy8vwzlr1arFsGHDsLW1pVu3btjb23Pu3Dmg5PUsLE8ChyhTLl26RL169QzPGzRowPXr10lPT+epp56ibdu2vPTSS3Tp0oU5c+aQlZWFp6cnr732Gh9++CEdO3bk9ddf5+rVq/mePywszPCLcf369QQEBFClShV0Oh2ffvopmzdvxsfHh8GDB3P8+PEild3KyoqXX36ZefPmkZWVZXj95s2bpKSkGN1X/fr1uXTpUqHqo2rVqtSsWdPo2MTExEKV6eLFi2zevJmgoCDD49KlS1y5csXwmTp16hi+r1u3rqFcd/9b2NnZUadOHRITE4mPj8fV1RVbW9t8r1u3bl2j51WqVCElJcUk9SwsTwKHKFOcnZ25ePGi4XlcXBxOTk7Y2tpiZ2fH2LFj2bZtG19//TXr1q0zjCn07duXVatWsXXrVm7dusX8+fPzPX/nzp25du0aMTExrF+/nu7duxve8/LyYvHixezfvz/fPvvCCAkJwdra2qg1Ub16dapWrWp0XxcuXMDZ2blQ9ZGSksL169eNjnVxcSlUeVxdXenVqxebNm0yPH788UdCQkIMn4mLizN8f/78eUO57v63SE9P5++//8bFxQU3NzcSEhKMxkMKyxT1LCxLAoewmDt37pCWlmZ4ZGRkEBoayoIFC7h8+TLXr1/n448/pkePHgDs27ePv/76C03TqFmzJjY2NlhbW/P7779z+PBh7ty5g4ODA1WrVsXGxibfa1pbWxMYGMjMmTNJSkqic+fOgBq83rJlC7dv38bOzg5HR0esra0B9Vf7jBkzjFoR96LX63n55ZdZvHix0eshISHMnTuXmzdvkpCQwKJFiwz3FRMTc89AV6tWLTp16sSsWbNITU3ljz/+4NtvvzUcez/ZAXXfvn1kZWVx+/Ztdu3axc2bNw2f+fLLL7l69SrXrl1jwYIFBAcHAxAaGsqaNWv49ddfSU9PZ+7cuTRu3JiHHnqI5s2b06hRI2bMmEFycjLp6ekcOnTovuUpqJ5F+SGBQ1jMW2+9RatWrQyPSZMmMWzYMNq3b0/v3r0JCQmhcePGvPrqq4D6y3jYsGE89thj9OzZk6CgIHx9fUlJSWHatGm0a9cOHx8f7ty5Y5gplZ+wsDCio6MJCgoy+qW1bNkyfHx8aNeuHZGRkbz77ruA6rL58ssvCxU4AJ544gnq169v9NqECROoXbs2gYGB9OvXDz8/PwYNGgTAmTNnCpxZNGPGDK5du0bXrl0ZPnw4Q4cOJSAgoFBl8fT0ZM6cOcyePZt27drx+OOPs2rVKqPPhISE0L9/f4KCgmjRogXDhw8HVMtg/PjxvPHGG3Tu3JnY2Fg+/vhjdDodOp2O+fPnc+nSJfz9/fH29mb16tWFKtO96lmUHzpNk42chKisOnfuzFdffSUD1KJIpMUhhBCiSCRwCCGEKBLpqhJCCFEk0uIQQghRJJViHtzRo0exs7Mr1rFpaWnFPrYikvrIIXVhTOrDWEWoj7S0NFq3bp3n9UoROOzs7GjevHmxjo2JiSn2sRWR1EcOqQtjUh/GKkJ95E6ImZt0VQkhhCgSCRxCCCGKRAKHEEKIIqkUYxxCiIojIyODuLg4UlNTLV2UAmVkZNxzjKCssbe3p0GDBvfM8XY3CRxCiHIlLi6O6tWr07hxY3Q6naWLc0+3b9+mSpUqli7GfWmaxpUrV4iLi+OBBx4o1DHSVZWPmTMhKsr4tago9boQwrJSU1OpXbt2mQ4a5YlOp6N27dpFasFJ4MhH27bQr19O8IiKUs/btrVsuYQQigQN0ypqfUpXVT78/CA8HPr0AV9fN/bsUc/9/CxdMiGEsDxpcdyDnx80agQ//ODEiBESNIQQSnp6Oj4+Pvj4+ODl5cWjjz5qeJ57N8X8xMTEMHTo0AI/c+PGDYKCgkxZZJOTFsc9REXBH3+o7z/9FPz9JXgIUd7MnKm6mHP/342KgoMHYdy44p3T1taW3bt3A7BkyRISExN58803De9nZmZiZWWV77GNGjVi/PjxBZ6/WrVqfPjhh8UrXCmRwJGP7DGNxYvhqaegb1/1XLqrhChfsscrs//vZv/fDg837XUWLlzImTNnSElJwdnZmQEDBvDWW2+RlpaGlZUVkydPplWrVpw9e5ZZs2axePFiwzGZmZmcP3+esLAwnn76aZKTk3nttdfYtGkTkZGRbNiwgerVq3Px4kUeeeQRXnvtNQDWrVvH/PnzqVOnDg888AB2dna8/fbbpr2xe5DAkY+DB3N+0N55J5Xff7cnPFy9LoFDiLJj6VL48suCP1OvHgQGgpsbxMdD8+Ywdap65Oe55+CZZ4pelgsXLvD111+j1+tJTk5m4cKFODo6cvbsWSZMmMA333yT55jLly+zaNEiMjIyCAoKon///nk+c/bsWX744Qesra3p1asXgwYNwtbWljlz5rBy5UqcnJwYPnx4oafSmoIEjnzkbsJ26XKLr7+257HHJGgIUR7VrKmCxrlz0LChem4OXbp0Qa9Xw8aZmZm8++67nDt3DhsbG86cOZPvMR07dkSn02Fra0utWrW4evVqnoy6bdu2NSzMa9y4MfHx8aSkpNCqVStq1aoFQFBQECdPnjTPjeVDAsd9eHsns3hxHXbsgF69LF0aIURuzzxz/9ZBdvfUpEnw2WcwebJ5/gjM/Qv/yy+/pH79+sycORNN02jXrl2+x1hb5/wK1uv1ZGZm3vczd+7cwdL778msqvto3TqF6tVh40ZLl0QIUVS5xzSmTVNfc6/RMpcbN27QqFEjAHbv3m3y9CgtWrTg119/5erVq2RmZrJp0yaTnv9+pMVxH7a20K2bChyaBrLuSIjyI/d4JeSs0TL3eOXTTz/NhAkT2Lt3Ly4uLjg6Opr0/DVr1mTMmDEMGDCAOnXq0KxZMxwcHEx6jYJUij3HS7KhSkxMDHv2NOeFF+D4cWjRwsSFK2cqwuY0piJ1Yay06qO81Lu5c1Vlnz8rK4uxY8fSvXt3AgICin2+/Or1XnVt1q6q/fv3ExgYiL+/P3PmzMnz/pIlSwgICMDPz49nn32W+Ph4w3uRkZEEBATQrVs3li9fbng9ISGB/v374+/vz4gRI0hJSTHnLQCQvRZHuquEEGXFF198Qe/evenZsye1a9emW7dupXZtswUOTdOYOHEic+fOZcuWLURHR3P48GGjzzRu3JhVq1YRFRVF+/btmTFjBgC3bt3i/fffZ/ny5axZs4avvvrKEFRmz55NWFgYO3bsoFGjRixdutRct2DQsKFqaUjgEEKUFaNHj2b16tWsW7eOSZMmlWr+LrMFjpiYGBwdHfH09MTa2poePXqwdetWo8/4+voa+v7atm1LYmIiAPv27ePRRx/FxcUFBwcHAgIC2L59OwBRUVH07NkTgN69e7NlyxZz3YKR4GDYswdu3SqVywkhRJlltsHxxMREXFxcDM/d3Nw4cuTIPT+/atUq/P4Zrbr7WFdXVxITE0lOTkbTNMMgkJubG5cuXbpvWdLS0oq9oUpqauo//XxVSU9vxNKl5/Hzq7zRI7s+hNTF3UqrPjIyMrh9+7bZr1NSmqaVi3JmK8rGU2YLHHePuWdlZd3zs+Hh4cTFxTFt2rR8j81+XpRz5mZnZ1eiwfHmzZvj4QFjxsDx4+6MGlWsU1UI5WVgsjRIXRgrzcHx8rBBUnnZyCmbjY1NvoPj+TFbV5WrqysJCQmG5wkJCUatiGzbt2/n22+/Zf78+YbVkdktjLuPzW5p3PqnvyghIQFnZ2dz3YIROzuV6DB7Wq4QQlRWZgscnp6eJCUlERsbS0ZGBmvXrqVbt26cPHnSsPz+4MGDzJo1i88//5zq1asbju3YsSNHjhwhISGBW7dusW3bNvz9/QHw8/MjIiICgNWrV5do+llRBQXBn3/CqVOldkkhRBkzePBg9uzZY/TakiVLmDJlSr6f79mzJ5cvXy4wXfoLL7xw326i5cuXG3V9de7cuWgFNyGzBQ69Xs/06dMZPXo0AQEBdOjQAS8vLyIiIti2bRsAH330EZcuXaJv3774+PgwcOBAABwcHBg3bhwDBw6ke/fuDBkyhHr16gEwduxY1q1bh4+PD2fPnmXIkCHmuoU8goPV11JepCmEKC4z7AMdGhrKhg0bjF7bsGED3bt3L/C4kqZL//bbb40Cx2effVbsc5WUWVeOd+zYMc+sp9x563Ovz7hbWFgYYWFheV53c3Pj+++/N10hi+CBB6BZM9VdNWaMRYoghCgKM+RVDwwM5KOPPiI9PR1bW1vi4uK4dOkSK1as4H//+x/p6emGP3hzy50uPSMjg4kTJxITE0OjRo0M3e8A48eP59SpU4bzjBgxgoiICOLi4hg1ahSOjo58/vnnjBw5kr179wLwySefGNKOPPPMM/Tr14/Lly8zePBgfHx8uHDhAhkZGcybNy9PEsXikJQjRRQUBAsWQEoKVK1q6dIIUclZIK96zZo1adWqFbt37yYgIIANGzYQHBzMCy+8gJOTE3fu3GHYsGH4+vri6emZ7zlWr17NnTt3WLt2LWfOnKFHjx6G98aPH290nsDAQHr16sWiRYuYP3++ISNutujoaH788UdWr15Namoqffv2xcvLi+rVqxMXF8czzzxDgwYNmD59Otu2bSM0NLTg+ioESXJYRMHBkJYGu3ZZuiRCiELJnVfdzc0kedVzd1dFRkbSvXt3Nm/ezMCBAxkyZAh//vknp0+fvufxBw8eNHRteXh40LJlS8N7RTkPwE8//URISAi2trbUqFEDX19fw2LrRo0a0aBBAwAeeOABLly4UKL7ziYtjiLq2hWqVFHdVdljHkIIC7FQXvWAgADef/99jh8/TmpqKg4ODnzzzTd88803VKtWjXfeeYf09PQCz5E7XXr2jNKzZ8/mOU9aWlqxy5lfSnZTkBZHEdnbg6+vDJALUS6YKa96tWrVaNeuHW+99Rbdu3fnxo0bODs7U61aNW7fvs2PP/5Y4PFt27Y1fObq1ascO3YMoMDzVKtWjeTk5DznateuHRs2bCA9PZ0bN26wc+dO2rRpU6L7ux9pcRRDcDCMHg2nT0OTJpYujRDinsyYV7179+689NJLzJ49Gw8PDxwdHRk1ahRVq1alxX3SaD/55JO88847vPTSS1SvXp2mTZsC0LJly3uep2/fvjz//PPUqlXLaBvaTp06cfjwYXr27IlOp2Po0KF4eHhw+fLlEt1fQSStejGO/f13aNoU5s2Dl14yRQnLD1ktnUPqwpikVTdW3laOl5m06hXVQw+ploZ0VwkhKiMJHMUUHAw7doCJd4QUQogyTwJHMQUFwe3bsHu3pUsiROVTCXrYS1VR61MCRzH5+anEh9JdJUTpsre358qVKxI8TETTNK5cuYK9vX2hj5FZVcVUtapa07FxI8yebenSCFF5NGjQgLi4OLPOGjKFjIwMw/qMss7e3t6wULAwJHCUQFAQjB0Lf/0FjRtbujRCVA42NjY88MADli7GfZWX2V/FIV1VJSDZcoUQlZEEjhJo1ky1NDZutHRJhBCi9EjgKAGdTnVXbd8O90lLI4QQFYYEjhIKDobkZLhPahohhKgwJHCUkJ8f2NhId5UQovKQwFFC1auDt7cMkAshKg8JHCYQHAzHjsH585YuiRBCmJ8EDhMIClJfN2+2bDmEEKI0SOAwgX/9Cxo0kHEOIUTlIIHDBHQ61V21bRtkZFi6NEIIYV4SOEwkKAhu3IB9+yxdEiGEMC8JHCYSEADW1tJdJYSo+CRwmEiNGtC5s0zLFUJUfBI4TCgoCI4ehfh4S5dECCHMRwKHCUm2XCFEZWDWwLF//34CAwPx9/dnzpw5ed6Pjo6mV69etGjRgk13/bb94IMPCAoKIjAwkIiICMPro0ePpmPHjvj4+ODj40NsbKw5b6FIWrUCNzcJHEKIis1sGzlpmsbEiRP55JNPePDBBxkwYABdu3alTZs2hs+4u7szY8YMFi5caHTszp07OXToEGvXriU9PZ2+ffvStWtXatasCcC8efPw8vIyV9GLLTtb7g8/wJ07arBcCCEqGrO1OGJiYnB0dMTT0xNra2t69OjB1q1bjT7j7u5Os2bN0Ol0Rq//8ccfeHl5YWtri4ODA56enuzatctcRTWp4GC4fh0OHLB0SYQQwjzM9jdxYmIiLi4uhudubm4cOXKkUMd6enry4YcfkpycTGpqKocPH6ZZs2aG98eNG4der8fX15dx48Zha2tb4PnS0tKIiYkp1n2kpqYW6Vh3dz16fVOWLbtCrVple0/k4ihqfVRkUhfGpD6MVeT6MGtXVW5ZWVmFPrZLly789ttvDBw4kFq1atGmTRusrKwAGD9+PK6urqSkpDB+/HgWLVrEqFGjCjyfnZ1dsff+Lc6+wR07wsGDdWjevE6xrlmWVeR9lItK6sKY1IexilAf9wp8ZuuqcnV1JSEhwfA8ISHBqAVyPyNHjmTNmjV89dVXpKam0rhxYwDq1auHXq/HwcGBPn36cOzYMVMXvcSCg+Hnn+HSJUuXRAghTM9sgcPT05OkpCRiY2PJyMhg7dq1dOvWjZMnT3LmzJkCj83KyuLixYsA7N27l1OnTuHr6wvA6dOnAUhPT2f9+vU0bdrUXLdQbJItVwhRkZmtq0qv1zN9+nRGjx5NWloaYWFheHl5MWPGDGrWrMnw4cM5dOgQY8eO5caNG+zZs4d58+YRGRlJZmYmzz//PNeuXcPFxYW5c+caxjHGjx9PfHw8VlZWdOjQgeHDh5vrFort0UfB2VmlHxk82NKlEUII0zLrhNGOHTuyZcsWo9fefPNNw/deXl7s3r07z3E2NjZERkbme84VK1aYtpBmoNerVkdkJGRmwj/DM0IIUSHIynEzCQqCK1fg0CFLl0QIIUxLAoeZPPGEWhAo2XKFEBWNBA4zqV0b2rWT9CNCiIpHAocZBQfDTz/B339buiRCCGE6EjjMKDgYNA3uyrQihBDlmgQOM3rsMdVlJeMcQoiKRAKHGVlZQWCgGucoQsYVIYQo0yRwmFlwMFy+DIXM7yiEEGWeBA4ze+IJ9VW6q4QQFYUEDjNzdgYvLwkcQoiKQwJHKQgKgv374do1S5dECCFKTgJHKQgOVoPjMi1XCFERSOAoBe3aQc2asopcCFExSOAoBdbW8PjjKnDctTGiEEKUOxI4SklwMMTHwy+/WLokQghRMhI4SklgoPoq3VVCiPJOAkcpcXOD1q1lWq4QovyTwFGKgoNh715ISrJ0SYQQovgkcJSi4GC1lez27ZYuiRBCFJ8EjlLUoQPUqCHdVUKI8k0CRymysZFpuUKI8k8CRykLCoK4ODh+3NIlEUKI4pHAUcqCgtRX6a4SQpRXEjhKWYMG8PDDsp5DCFF+SeCwgKAg2LMHbt60dEmEEKLoJHBYQHAwZGTAjh2WLokQQhSdBA4L6NwZHByku0oIUT6ZNXDs37+fwMBA/P39mTNnTp73o6Oj6dWrFy1atGDTXb9FP/jgA4KCgggMDCQiIsLwekJCAv3798ff358RI0aQkpJizlswC1tb6NZNDZDLtFwhRHljtsChaRoTJ05k7ty5bNmyhejoaA4fPmz0GXd3d2bMmEFwcLDR6zt37uTQoUOsXbuWVatWsWDBAq79s33e7NmzCQsLY8eOHTRq1IilS5ea6xbMKjgYzp6FkyctXRIhhCgaswWOmJgYHB0d8fT0xNramh49erD1ri3w3N3dadasGTqdzuj1P/74Ay8vL2xtbXFwcMDT05Ndu3YBEBUVRc+ePQHo3bs3W7ZsMdctmJVMyxVClFfW5jpxYmIiLi4uhudubm4cOXKkUMd6enry4YcfkpycTGpqKocPH6ZZs2YkJyejaRoODg6Gc166dOm+50tLSyMmJqZY95GamlrsY+/Hw8ODlSszCAo6b5bzm4M566O8kbowJvVhrCLXh9kCh3ZX531WVlahj+3SpQu//fYbAwcOpFatWrRp0wYrK6tin9POzo7mzZsX+vq5xcTEFPvY++nVCz75xI6GDZtTrZpZLmFy5qyP8kbqwpjUh7GKUB/3Cnxm66pydXUlISHB8DwhIcGoBXI/I0eOZM2aNXz11VekpqbSuHFjQ0vj1q1bhnM6OzubtuClKCgI0tNh505Ll0QIIQrPbIHD09OTpKQkYmNjycjIYO3atXTr1o2TJ09y5syZAo/Nysri4sWLAOzdu5dTp07h6+sLgJ+fn2GW1erVqwkICDDXLZidjw9UrSrjHEKI8sVsgUOv1zN9+nRGjx5NQEAAHTp0wMvLi4iICLZt2wbAoUOH8PHxYdu2bUyePJnQ0FAAMjMzef755+nUqROzZs1i7ty52NraAjB27FjWrVuHj48PZ8+eZciQIea6BbOzswN/f1nPIYQoX8w2xgHQsWPHPLOe3nzzTcP3Xl5e7N69O89xNjY2REZG5ntONzc3vv/+e9MW1IKCgmD9evj9d3joIUuXRggh7k9WjltY9hIWaXUIIcoLCRwW5uEBTZvKOIcQovyQwFEGBAVBVBTcvm3pkgghxP0VKnAsW7aM5ORkAKZOnUr//v05cOCAWQtWmQQHQ2oq5DPcI4QQZU6hAseqVauoVq0ae/fuJT4+nilTpjBjxgxzl63S6NoV7O2lu0oIUT4UKnBk55LatWsXTz75JJ6enkVaCS4KVqUK+PpK4BBClA+FChyNGzdm9OjR7Ny5E29vb0O3lTCd4GA4dQruszZSCCEsrlDrOGbOnMmRI0fw8PCgatWqXL16lalTp5q7bJVKdrbcTZtg1CjLlkUIIQpSqBbHsWPHePjhh6lduzYbN27k66+/xtXV1dxlq1QeekhNzZX1HEKIsq5QgWPKlCnY29tz8uRJPvvsM2rVqsUbb7xh7rJVKjqd6q7asQPS0ixdGiGEuLdCBQ5ra9WjtX37dgYPHsyQIUO4efOmWQtWGQUFQXIy7Nlj6ZIIIcS9FSpw2NjYsHz5ctasWYOPjw9ZWVlkZGSYu2yVjp+f2o9cuquEEGVZoQLHhx9+yLVr13jnnXdwcXEhPj6eQYMGmbtslU61ampNh0zLFUKUZYUKHPXq1WPIkCFYW1tz4MABatSoQf/+/c1dtkopKAhOnIBz5yxdEiGEyF+hAkdUVBTdu3dn2bJl/N///R9hYWHslG3rzEKy5QohyrpCreOYO3cu33//vWEKbnx8PC+88IJhVz5hOp6e0KiR6q4aPtzSpRFCiLwK1eLIzMw0Wrfh5ubGnTt3zFaoykynU91V27er/ciFEKKsKVTg8PLy4tVXXyUqKoqoqCheeeUV2rdvb+6yVVrBwXDzJkRHW7okQgiRV6G6qiZNmsSqVavY9E/He5cuXQy6xEQAACAASURBVOjdu7dZC1aZ+fuDjY3qrpLeQCFEWVNg4AgODjZkxtU0zfD6r7/+ypdffsmGDRvMWzpLmTkT2rZVCyuyRUXBwYMwbpzZL1+9OnTpogbIJXu9EKKsKTBwhIeHl1Y5ypa2baFfPwgPB1dXFTSyn5eS4GAVoy5cgPr1S+2yQghxXwUGjurVq5dWOcoWPz8VJHr04IH69eHyZVi50rgFYmZBQSpwbNoEQ4eW2mWFEOK+ZM/xe/Hzg6Ag7E+eVAmkzpyBXN115taypWppyHoOIURZI4HjXqKiYOdOrg4YAFlZMGwYBATA6dOlcvnsbLlbt4LMfBZClCUSOPKTa0wjcdIkNb3JwQH274eHH4YPP4TMTLMXIygIkpLUZYUQoqyQwJGfgwfVGEf2mEa3brB2Lbzyimp1vP46dOwIv/1m1mIEBICVlSQ9FEKULRI48jNuXN6BcD8/ePddWLMGvvsO/voL2rSBd94x285Ln38OLVoYB46oKDVbWAghLMWsgWP//v0EBgbi7+/PnDlz8rwfHR1Nr169aNGihWFxYbaPP/6YwMBAAgMDeeuttwwpTkaPHk3Hjh3x8fHBx8eH2NhYc95CXjodPPUUxMTAgAHw3//Co4+aZZl327ZqSOXIEUhIyOlBa9vW5JcSQohCM1vg0DSNiRMnMnfuXLZs2UJ0dDSHDx82+oy7uzszZswgODsl7D9iY2PZsGED69atY8OGDZw/f94oG++8efPYvXs3u3fvxtPT01y3ULDatWHpUtUcSE5WK/ZGj4Zbt0x2CT8/+Ogj9f0LL+QsJSnFWcFCCJGH2QJHTEwMjo6OeHp6Ym1tTY8ePdi6davRZ9zd3WnWrJlhdXo2nU5HZmYm6enpZGZmkpGRQd26dc1V1JIJCoJjx+DFF+GTT9Q82s2bTXb6YcPA0VENsfj4SNAQQlheoXJVFUdiYiIuLi6G525ubhw5cqRQxzZr1oywsDC8vb2xsbGhZ8+ePPLII4b3x40bh16vx9fXl3HjxmFra1vg+dLS0oiJiSnWfaSmphbu2FGjqNKhA27vvINdUBDXe/Uicdw4spycinXdbAcOVEXTGuDsnMXq1TZ06HCLOXMu4OSUVaLzFleh66MSkLowJvVhrELXh2Ym27dv10aOHGl4vnnzZu3VV1/N97OvvfaatnHjRsPz+Ph47emnn9auXbumpaSkaAMGDNB27typaZqmXbhwQcvMzNRu3rypvfjii9qnn35637KcOHGi2PdR5GNv39a0t9/WNGtrTXN21rTwcE3LyirWtXfs0LQ6ddTXjAxNe+45TQNNq11b0zZvLtYpS6wkdVnRSF0Yk/owVhHq4173YLauKldXVxISEgzPExISjFogBdm9ezcPPfQQTk5OVKlSBR8fH37++WdAbWOr1+txcHCgT58+HDt2zCzlLzZ7e5g+HQ4dAnd3NTDx5JNw8WKRT5V7VrC1NSxeDAsWqCm6gYGqdyw52Qz3IIQQBTBb4PD09CQpKYnY2FgyMjJYu3Yt3bp14+TJk5w5c6bAY93c3Dh06BApKSlkZGSwf/9+PDw8ADj9z8rt9PR01q9fT9OmTc11CyXzyCNq5d4HH6gxjxYt4IsvipS2JL9ZwS+8AGfPwmuvwWefQevWsG+ficsuhBAFMFvg0Ov1TJ8+ndGjRxMQEECHDh3w8vIiIiKCbdu2AXDo0CF8fHzYtm0bkydPJjQ0FABvb286depEjx49CA0NpWHDhoSFhQEwfvx4unTpwuOPP461tTXDy/L+qtbWarHgb7+pKbvDh6vFhH/8UaLT2tvDrFlqem5GhprQ9fbbsmOgEKKUlHKXmUWU6hjHvWRladrChZpWo4am2dtr2gcfqIGLEkpKyhn7aN1a0377zQRlLUBF6Lc1FakLY1IfxipCfZT6GIe4i04Hzz8PJ07AE0/AG29Ahw7wyy8lOm2NGmrsY80aNYzy2GOqNVIKqbSEEJWUBI7SVr8+RETA99/D+fPg5QUTJ0JqaolO26OHWk4SGqpikr8//PmnicoshBC5SOCwBJ1OzbY6cQIGDlQ5sB59FPbuLdFp69aFVavg66/h6FFo1Uq1RkpxGxEhRCUggcOSatdWv+U3bYKUFPD2hpdfhps3i31KnQ6eeUaNx7drp1ae9+ihcl0JIYQpSOAoCwID4fhxFTQ+/RT+9a8S51Jv2FBtAvXRR7Btm8qEsmqVicorhKjUJHCUFQ4OMHcu/PgjVKsGISEqbXtEhPHnipBXXa+HMWPg8GFo3Bj69lWtkevXTV98IUTlIYGjrOnUSQ1QTJqkZlz17q2+17Ri51Vv3lwtEpw8Gb75Ro19bN9upvILISo8CRxlkZ0dTJumNuJ46CGVwqRVqxLlVbexgSlTVACpWlXtLjhmjBpaEUKIopDAUZa1aqXGPrp2VXNt7e3Vnucl0LatikdjxsDHH6vesIMHTVReIUSlIIGjrNuzRwWPPn0gLk7lwPr99xKdskoVNWi+fbtqcXTsqLqxMjJMVGYhRIUmgaMsyx7TCA+HlStVEyE+Xi0P37OnxKf394dff4Wnn1Y9Yx07qh1xhRCiIBI4yrLcedVBTdddulSNgQQEqJHuEnJyUktJVq1SWXcffVS1RrIss0+UEKIckMBRluWXV33QIDh5UuW5evppNXBugqXhvXurRYNPPAGvvqri0rlzJT6tEKICksBRHtWqBVu2qCAyaRL85z8myanu6qqSJS5erBo7Dz+sWiOSskQIkZsEjvLKzk51W02Zon67BwXBtWslPq1OB889p8Y+WreGZ59VAWT1auPPFWEdohCigpHAUZ7pdGo61NKlasV5p04mS4n7wAMqOMyapXrG+vZVvWJQ7HWIQogKQgJHRTB4sOq6SkiA9u3hwAGTnFavV1vUHjkCHh6qV6x7dw/69i32OkQhRAUggaOi8PVVy8KrV1ffmzCjYcuWKgO8ry+cOWNHUpJKnHjrlskuIYQoRyRwVCSenrB/v5pT++9/wwcfmGxke+9etXh98OArWFvD//6nsqEsWSJTd4WobCRwVDR166ol4X37qum8I0fCnTslOmXudYgTJlxi40a1/sPJSU3oat++xHtQCSHKEQkcFVGVKvDddzB+PHz+OXTvDjduFPt0d69D9PNTs6yefRaWLVOL2bt0gQEDZO2HEJWBBI6KSq+H996DhQvVgESXLmqP82LIbx2inx+8+aZag3jyJLzzjto6pFkz9X1ysgnuQQhRJkngqOief17tJnj2rOpTOnzY5JeoVg2mTlUB5Mkn4b//VQFk2TIZ/xCiIpLAURk8/rgahLCxAR8fWLfOLJdp2FClz9q7F9zc1CzhTp3UeL0QouKQwFFZtGypfoN7ekKvXjBvntku1amTWkry9ddqzKNjR5UdJS7ObJcUQpQiCRyViZsb7NoFYWEwerTazSkz0yyX0uvV/uanTsHbb6us8E2bqi4t2XVQiPJNAkdlU62aWhz4yitqf4/evc06ku3goFKVxMaqeDVlimr0fPutJE8Uorwya+DYv38/gYGB+Pv7M2fOnDzvR0dH06tXL1q0aMGmTZuM3vv4448JDAwkMDCQt956izv/rEVISEigf//++Pv7M2LECFLkz9eis7KCOXNUd9X69WrcIz7erJds3Bi+/x5271ZLTQYOVBO9ZNtaIcofswUOTdOYOHEic+fOZcuWLURHR3P4rhk97u7uzJgxg+DgYKPXY2Nj2bBhA+vWrWPDhg2cP3+enTt3AjB79mzCwsLYsWMHjRo1YunSpea6hYrvpZdg7Vo1Hap9e7Uhh5l5e8NPP6nU7adPQ7t2MGQIXLxo9ksLIUzEbIEjJiYGR0dHPD09sba2pkePHmzdutXoM+7u7jRr1gydTmf0uk6nIzMzk/T0dDIzM8nIyKBu3boAREVF0bNnTwB69+7Nli1bzHULlUNoqNqGNjMTOneGzZvNfkkrK5W6/fff1RrF775T4x/vvgu3b5v98kKIErI214kTExNxcXExPHdzc+PIkSOFOrZZs2aEhYXh7e2NjY0NPXv25JFHHiE5ORlN03BwcDCc89KlS/c9X1paGjHF3Ew7NTW12MeWG/b2WC9bhvvIkdiFhpIwaRLX+/XL96Omro9nngE/PxtmzXJm4sQazJ+fzmuvXSIo6CZ3/T1R5lSKn40ikPowVpHrw2yBQ7tr5DOrCCvBEhIS+Omnn4iKisLOzo6hQ4eya9cuHnvssWKd087OjubNmxf6+rnFxMQU+9hypXlzNeDQrx9uU6bglpKiVp7rjRul5qiP5s3VlrU7d8Irr9jy2msNiIhQe5+3aWPSS5lUpfnZKCSpD2MVoT7uFfjM1lXl6upKQkKC4XlCQoJRC6Qgu3fv5qGHHsLJyYkqVarg4+PDzz//bGhp3Ponn3dCQgLOzs6mL3xlVb26Whw4YoTa3u+pp0q178jXF37+WWVJiY0FLy8YOlRtMyKEKDvMFjg8PT1JSkoiNjaWjIwM1q5dS7du3Th58iRnzpwp8Fg3NzcOHTpESkoKGRkZ7N+/Hw8PDwD8/PyIiIgAYPXq1QQEBJjrFiona2uYPx8+/FBN2/X3h0J0B5qKlZXKkvL77/D66/B//6fStwcH5x1+ke1rhbAMswUOvV7P9OnTGT16NAEBAXTo0AEvLy8iIiLYtm0bAIcOHcLHx4dt27YxefJkQkNDAfD29qZTp0706NGD0NBQGjZsSFhYGABjx45l3bp1+Pj4cPbsWYYMGWKuW6i8dDoYO1at2vvlF7Xw4uuvjT9j5t/ajo7q9CdOQLdusGkThISoBYSaJtvXCmFRWiVw4sQJixxbIRw4oGlOTpqm02na7NmqPnbs0LQ6ddTXUrJtm6Y1bqxpoGkNG2qag4OmrVxZapfPV6X/2biL1IexilAf97oHWTkuCtaundp03N0dxo7FIyhITeF9/nm1k1MpjYF066a6r0JCVP6rW7fUXlXt2qlWyKFDkolXiNIigUPcX+PGqsuqTRvszp2DtDQ146pNG5VTpFkz6NMHJk+GFSsgJgYyMkxejD171OLBiRNzdh+0slKBo21bqFdPvbZyZYn2rRJC3IfZpuOKCubIETh3jssjR1J3xQq1n3m1amoj8uPH1deIiJw/+21tVUBp2dL40bhxnim+hZF7+1o/PzVmn/28ZUs1cB4ZqYqwZIka4/f2Vo2j0FBVlLK+LkSI8kICh7i/XL+1/3Z1pe6//53zW3vq1JzPpaaqebTHjuU8oqNVRsNsVavCv/6lHrkDSr16Bf5mz2/72vBw9bqfn0rbPmiQ2l593z4VRCIj1cys118HDw8VQEJC1LRfe3vzVJUQlYEEDnF/uX9rx8Tk/a2dzd4eWrdWj9xu3lTTo3IHlE2bVNMgm5OTcSDJDix16gAwjplAWyDnen5E4cdBYJzhteyWhrc3vP++Gg/ZsEEFkUWLVF7HqlXVmEl2IHF3N3mNCVGhSeAQ9zduXN7X/PzybkR+L9WrqySK7dsbv/7336qbK7ur69gxlbjq+vWcz7i4qADi6Kj2pH3vPZWn5Oefc1o9BWjYUK1nHDFCjePv3JnTGsneCLFVq5wurfbtVfARQtyb/BcRllOnDnTtqh7ZNE2leM/dOjl2TO1emJwML7+sHlZWEBCgMvvWrKmCy31+41epohYSBgerlkdMTE4QmTlTxaRatSAwUAWRoCCoXdvMdSBEOSSBQ5QtOp0a76hXTyWwypaVBWfPwoQJamMPDw84fDhnOXnVqipHSfv20KGD+lq/foGXadFCPd54QzVytm5VQWTDBjUso9erU2W3Rlq1UnMC2rY1bmxFRaleu/waZkJURDIdV5QPej389Rds3w6TJsG1a6pb68wZ+OYbta4kLQ3mzlVTgxs0UIMX//43zJoFP/5Y4J61Tk7qo0uWqNxYBw6oab9paWrr29at1el271Zbtm/YoI6TFeyiMpIWhygf7p6P6+eX83zAAPUA9Zv+6FHVtXXggPq6cqV6z8oKHnnEuFXy0EN5pgfr9WphYfbiwoQE2LhRtUa2bFFj/aGhUL9+E65dU9vh3pW4WYgKTQKHKB/uNx83m51d3oH4S5dUEMkOJMuWwWefqfdq1lQRIjuQtG+vBjpycXVVCwv/8x9IT1eNl7feggMHbAHVRfXmm/Dww9Cpk3p07AhNmsjaEVExSeAQ5UNJZnY5O0NYmHqA2u0wNjYnkOzfr2ZsZS9ebNrUuFXSqhXY2ABg+9FMalq35fRpP0aOvEx4eF0+6RNF7TMHmaUfxzffwIIF6jR16+YEkk6dVKukShUT1IUQFiaBQ1Q+VlY5ixCfe069dvOmSniVHUy2bFE53UGtT3nsMejQgT8vVaPRsr5s+WAF9iFuPP/gMdxf78f5WeFsHqtiUkyMWveY/VizRp3GxkZlaclukXTqVOD4vRBllgQOIUCtNcndgtE0tXowO5AcOACffMIDaWkA1Br3OOkfN8A2MZFLXUJI2bATdEexcnKiZc2atGzqxPB2TjDFib/vOBF9rAbR+/Xs26d6yebMUZdp2NC4VZKrcVOwmTNleldZVEn+XSRwCJEfnQ4aNVKP7P3X09Ph119VIFm4ENvffgNHR5x/3YFz0g+wPf9T1QF66HT0cHQEJyeymjlxy9qJS+lOxN104vd1Tpz/riZf48RtWyfqPuRE49ZONGvvRCsfJ2p61FTJJHMPmLRtazxZIPfkAWE5uf9dXF0r7L+LBA4hCsvWVq0VuXkT4uNzEj6Gh4OPj3r9+vWcx7Vrxs//eeivXaPG9evUSD/Ng5nX8dVfB26qa6QDx/95LM+5dJZOT3pVJ/S1nLCp68S5JCdquDWnZkiIKtMvvxDzwhwi93Xm9UIu6Bdm4OcHX34JvXtTp18/WL3aeFJHBSGBQ4iiKCjho5+fWhBSHHfuQFKSIbikJlznzOHr/HX0Ogmx17j253Xskq/jlHyduvHXcbG/TnLyNaraWGP3448ANJ81jGZWI2B507w5v5o0UWM7wrQyMlRmg+xZewcOqIkXmkbdhQvVz4avr6VLaXISOIQoisImfCwqa2uV3+SfHCf2QItQaPHP25qmNrLatw9W/zPoXudYFOHp/VjIy4xkAevdR9HEQ6NJ6jHqHDiE1YoV6DRNncDeHpo3Nw4mLVuqQRaZM1w4uce9sh+HD+dsZla3bs5svBUruGNtjXV4uAokixerlmEFIYFDiKIoacLHYtLp1Czhpk1hyBAgKoqsf/fjf4+EM2mHH6fcH2fOhX70OR/OTt4FoGHtZLo3icGn1jEe1h/D/cZxHKKi0GXPFgM1KSC/NPcuLhJQkpJyZtplPxIT1Xv29mqK3Asv5Kz/adxYZdHs1w/WruX3OnVovngxfPyxGvsYNAjefVcF63JOAocQ5dHBg/zyVjhz3/Nj0iT47DM/XvkgnI23DnLI34+jR+Ho0WocOOrF4igv/pkMhr09dGh9ncAGx+ngcIymd47jfOkY1mvWqL+Ks9WunTeY/OtfeRZHVphZRHfuwG+/5dvlBKidwAIDc4LEvaa/3d0i/egjlYxz9myVwWDlSnj1VRg/HmrUKN17NCEJHEKUQ1Ftx+XJwPJEPz/Cw/3w6wJduuR8NiNDJRFWwQSOHnXig+jOXL3aGVANiwcfBJ+Ol/BzPk5r62M0vnWMqn8eQ7dsmfE+vG5uxsHEwUEl+VqxovzMItI0OH/eOEj8/HPeLqeBA9VXLy+VYaAw8guW3burx7lzKvHZe++pzWGmTlU51sphHn+dpmWH1IorJiaG5s2bl/qxFZHURw5L1kVJ/9DXNLhwIXcwUY/Tp3M+U7cutH5Eo+uDF+hU4xgtso5RN/EY+hPH1MZc2b9oAfR6MlxcsLlyhastOnPO9iFae1dXXWE1ahh/ze81W1vzVciIEeprdpD46SeVgAxUipo2bXJaEtldTiboprvnz8ehQ/DaaypjpqenSrkcGlomuwbvdQ8SOMx4bEUk9ZGjItbFjRtqqUruYPLbb2oJC6iurocfhkdbZeLt/hdOccf4Zfkxxjh/i8PZ46TVciXuenUaON7ALu1mgRmJjdjaFhxg7heAjh+HMWPUan83N1i6FObPV62gc+eMu5xyB4mHHy550LqHAn8+NA3WrlVR/tQp8PdXWZwffdQsZSmue91D+WsjCSHMpkYN1c1VUFfXkSOw8gcrFl5tAjTBlxoMP/sRXzpOYMDVL9jw5Oc0GeaHhwc0bnAH+zu31BqXGzfU13t9f/drly+rtPnZr9+6df8bCAkxvpmWLWHoUBUk2rYtfJeTuel00LOnKu/nn+ekWH7mGZg+XW0LUIZJ4BBCFMjGJmdIY9Ag9ZqmQVwcnF8axSP/68eo2uEsPe/HWv3jfPtDP/r9EM5O/NDprKlf3wkPDyc8PMjzcHYuQg9NVpYKHgUFodWrYccOtUvk3LllsvvHiI0NvPQSDB4M//ufGkwPD1ddWePGqdZUGSSBQwhRZDqd2tjK3eYgR/4bzob3VLbgFSv8iHkpnK8uHeTHjn6cOYPhsXWrGlfJrWrVvMEk+9G48V3ZhPV61YqoUSNPdsiZM+Fx6yge/XUK/0wz40jjJ9l6x698TO5ydIQZM2DkSJWzf/p0+OILmDZNJeIsYwPoZas0QohyJffsLlfXv/n3v+vS55/ZXYPyWdqSmqo2cswdULIf27erbeVzq1//3oEl91KTx62jcH+9H0dmhfPoWD+OOPnh/no/Hp8VDpSjdB+NG6sdLceMUa2OF15Q60A++ACCgspMC8qsgWP//v1MnjyZjIwMwsLCePXVV43ej46OZubMmZw6dYrZs2cTFBQEwL59+3jzzTcNn7t69SozZ84kJCSE0aNHc/DgQWz+mUO9cOFCPD09zXkbQoh7KOpCent7NZEov/+ympYzrHH6dN6gsnRpzhg3qNZIdhAZdvUge3qGM2mqH/1PwqpVfmz5IJw2dw5SrgJHtvbtYc8e+OEHtUtYSIhaDzJrltrF0sLMFjg0TWPixIl88sknPPjggwwYMICuXbvSpk0bw2fc3d2ZMWMGCxcuNDq2Y8eO7N69G4Dk5GT8/f3x8fExvD9v3jy8KtDyfSHKK1MupNfp1JiHs7PK2nG31FQ4ezb/1srA0+MMrZXsXycdJvjh6upHvdVQr556uLnlfJ/9qFWrzPwhb0yng9691RqQzz5T3VaPPgrPPqu6surVs1jRzBY4YmJicHR0NLQGevTowdatW/MEDgBdAf9qW7dupX379jg4OJirqEKIcsDeXs2mbdYs73uaBhERajggIAA2bYIePdTY88WLasbrrl1w9WreY21t8waU/AKMk9P9A4xZFtLb2qquq2eeUSlLPv4Yvv8e3ngDXn9dLcIsZWYLHImJibi4uBieu7m5ceTIkSKfZ/369Tz11FNGr40bNw69Xo+vry/jxo3D9j7zsNPS0oiJiSnytQFSU1OLfWxFJPWRQ+rCmCXr48CBqowdW585cy7Qvn0KoaHq+ezZ6nm2tDQdly9bc+mSely+bJ3ruQ1Hj1qzdas1N27kzSRsa5uFs/MdnJ3vULeueqjnGYbvHRxs6NOnHrNnX+CRR1JZsuSsoRwxMYVc01KQoUOxeeIJnOfMocbUqWTMn8/l0aNJ6tWrVLMfm7WrKres7P2ci+Dq1ascO3aM+fPnG14bP348rq6upKSkMH78eBYtWsSoUaMKPI+dnZ0sADQRqY8cUhfGLFkf69bBqlXg59cIUImAGzWCgwcbUZwipaRAfLxqrWR/vXhRz8WLtsTH23L2rMpUnDsbSzZbWxg6tBGurm5cuWJLv36QmdmIuDiV37BhwxLuPd+8OTzxBOzbh81rr1Fv0iTqhYer8Y8nnijBifO61x8CZgscrq6uJGQv6wcSEhKMWiCFsXHjRvz9/Y1aFPX+6ddzcHCgT58+rFixwjQFFkKUW6ZOWly1qtrCpEmTgj9365YKLDnBRT02bYLjx22pUQOWL8/Zvj5b3boqgDRqZPw1+/s6dQox7tKxI+zdqxInvvmmSsIYGAgtWkBYmFkTT5otcHh6epKUlERsbCxNmjRh7dq1jB8/npMnT2JjY4OHh8d9z7Fu3TrGjBlj9Nrp06dp0qQJ6enprF+/nqZNm5rrFoQQokAODvDQQ+qRLSoKvv6af9a11GXTJpUO/9w5Nbh/7lzO97GxsHlz3mnI9vb5B5Tsrw0a/JMpRadTSSZ79IBPP4X//peszVvQPv0Mq2+WQZ8+EBVF+pP9WP1UOP1NdN9mCxx6vZ7p06czevRo0tLSCAsLw8vLixkzZlCzZk2GDx/OoUOHGDt2LDdu3GDPnj3MmzePyMhIAOLi4rhw4QLt27c3Ou/48eOJj4/HysqKDh06MHz4cHPdghBCFEnu5MDZ61pyZzH29s57jKapXYZzB5bcASYyMicnYzadTqXhygksdjRqNJYm84bQYMl0PLfPQ9+3L7pu3Ug/9Av9tHDG9DfdtGRJcmjGYysiqY8cUhfGpD6MZ1Vl14cpeonS0lSKl7tbLLm/Zu+5AtCEP1hLGC2IZW6VN2kV+X6xuu0kyaEQQpiZuTaItLMreMwle/FkdhDJ2n4ety/+ZtqdSbym+4xqBGLKhZB6k51JCCGERWQvnmzbFvrUiqLnN/34T9Vw7kyaxtPW4aQ/2U/1o5mIBA4hhKhATn93UI1pRPgxbRqMifCjnxbO6e8Omuwa0lUlhBAVyKom4xgTkdM95ucHRPix6qAfpkoULIFDCCEqEHONs+QmXVVCCCGKRAKHEEKIIpHAIYQQokgkcAghhCgSCRxCCCGKpFKkHDl69Ch2dnaWLoYQQpQraWlptG7dOs/rlSJwCCGEMB3pqhJCCFEkEjiEEEIUiQQOIYQQRSKBQwghRJFI4BBCCFEkEjiEEEIUiQSOAuzfv5/AwED8/f2ZM2eOpYtjMfHx8Tz77LP4+PgQEBDAsmXLLF2kMiErtbsyUQAABbhJREFUK4t+/foxYMAASxfFoq5evcqIESPo3Lkz3bp148SJE5YukkV9++23BAcHExwczKhRo7h165ali2RyEjjuQdM0Jk6cyNy5c9myZQvR0dEcPnzY0sWymBdffJFdu3bx/fffs3DhQv744w9LF8nivvvuO9zd3S1dDIubPHkyrVu35scff2TNmjXUq1fP0kWymKSkJObOnct3333Hxo0bcXBwYOXKlZYulslJ4LiHmJgYHB0d8fT0xNramh49erB161ZLF8si3NzcaNu2LTqdjtq1a/PAAw9w6dIlSxfLoq5cucLGjRsZOHCgpYtiUZcvX+bnn39m2LBh6HQ6HBwccHJysnSxLEbTNDRNIy0tjczMTFJTU3F2drZ0sUxOAsc9JCYm4uLiYnju5uZGYmKiBUtUNvz555/89ddftGrVytJFsaj333+fMWPGYGVlZemiWNTZs2dxc3PjzTffJCQkhAkTJpCSkmLpYlmMk5MTr7/+Ok888QTe3t7cuXOHkJAQSxfL5CRw3MPdmViysrIsVJKy48aNG4wZM4Zp06bh4OBg6eJYzP79+9Hr9Xh5eVm6KBaXmZnJiRMnGDBgAOvXr8fKyopFixZZulgWk5KSwqpVq9iwYQO7d+/GxsaG5cuXW7pYJieB4x5cXV1JSEgwPE9ISDBqgVQ2aWlpjBo1imeeeYauXbtaujgWdeTIEaKjo/H39+ell17i2LFjjBgxwtLFsghXV1fq1KmDl5cXer2exx9/nJiYGEsXy2KOHDlCjRo1qFevHtbW1gQEBFTIsVEJHPfg6elJUlISsbGxZGRksHbtWrp162bpYllEZmYmr7zyCt7e3vTt29fSxbG4kSNHsmfPHnbs2MEnn3xCy5YtWbBggaWLZRGNGjWiVq1axMbGAhAdHU3Tpk0tXCrLcXNz48SJE1y9ehVN09i7dy8eHh6WLpbJWVu6AGWVXq9n+vTpjB49mrS0NMLCwipt18RPP/3Ejh07OH78uKHZPWnSJB5//HELl0yUBVOnTuWNN94gPT2dpk2b8t5771m6SBbj4eHBf/7zH/r164der8fT05MhQ4ZYulgmJ2nVhRBCFIl0VQkhhCgSCRxCCCGKRAKHEEKIIpHAIYQQokgkcAghhCgSCRxClAOdO3e2dBGEMJDAIYQQokhkAaAQJrJp0yYWLVpEZmYmDz74IO+++y5du3alV69eJCYmcuPGDd577z3q1q3L5cuXmTBhAomJiVSvXp3p06fj4eFBWloa7777LkeOHAFg6NCh9OrVC4DZs2ezfft2qlevzqeffkrt2rUtebuiEpMWhxAmEBcXx/Lly/nmm2/44YcfcHd3Jzw8nFu3buHt7c3s2bPp3bs3s2fPBmDGjBn4+vqybt06nnvuOd5++20AFi1aRFZWFmvXrmXdunX4+voCcPPmTVq1akVkZCQdOnRg1apVlrpVISRwCGEKP/30ExcuXGDo0KEMHjyYPXv2kJiYiI2NDR07dgSga9eu/PzzzwAcPHjQ0JIICAjgzJkzZGRksG/fPgYOHIhOpwMw7G1hZ2dHQEAAAK1btyYuLq60b1EIA+mqEsIENE2jS5cuTJs2zej1ZcuWkZWVhZWVFXfu3CnUubKDRm62traG7/V6PZmZmSUrsBAlIC0OIUygXbt27Nixg/PnzwOqa+ncuXNkZmYSGRkJQEREhCFRZtu2bVmzZg0A27Zto0mTJtjY2NClSxeWL19u2A/m6tWrFrgbIQomgUMIE3B3d2fKlCm8+OKLhISE8PTTTxMfH0/16tX5448/6N27N9u2bePVV18FYNy4cezYsYOQkBAWL17M9OnTAXjuuefQ6/UEBwcTGhrKjz/+aMnbEiJfkh1XCDPq3Lkze/futXQxhDApaXEIIYQoEmlxCCGEKBJpcQghhCgSCRxCCCGKRAKHEEKIIpHAIYQQokgkcAghhCiS/wfXDQWt7KqxaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn_jovi.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
