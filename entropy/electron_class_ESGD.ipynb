{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.3\n",
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "## Import libraries\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from   matplotlib import pylab\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(697)\n",
    "\n",
    "from sklearn            import preprocessing\n",
    "from sklearn            import metrics\n",
    "from sklearn.metrics    import confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.datasets   import make_classification\n",
    "from sklearn.neighbors  import KNeighborsClassifier\n",
    "from sklearn.ensemble   import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ''\n",
    "#if torch.cuda.is_available():   \n",
    "#    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#def to_numpy(tensor):\n",
    "#    '''converts a GPU tensor to a numpy array'''\n",
    "#    return tensor.cpu().detach().numpy()\n",
    "\n",
    "# Bunu bu aşamada yapmıyoruz. Sebebi data'yı cpu'da oluşturup sonra batch batch to.device ile gpu'ya aktaracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m Key name:\u001b[1;m ['correctedAverageMu', 'em_barrel_Lr0', 'em_barrel_Lr1', 'em_barrel_Lr1_fine', 'em_barrel_Lr2', 'em_barrel_Lr3', 'eventNumber', 'mcChannelNumber', 'p_ECIDSResult', 'p_Eratio', 'p_LHLoose', 'p_LHMedium', 'p_LHTight', 'p_LHValue', 'p_Reta', 'p_Rhad', 'p_Rphi', 'p_TRTPID', 'p_TruthOrigin', 'p_TruthType', 'p_charge', 'p_chi2', 'p_d0', 'p_d0Sig', 'p_dPOverP', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_e', 'p_et_calo', 'p_eta', 'p_f1', 'p_f3', 'p_firstEgMotherTruthOrigin', 'p_firstEgMotherTruthType', 'p_iffTruth', 'p_mean_charge', 'p_mean_chi2', 'p_mean_d0', 'p_mean_deta', 'p_mean_dphi', 'p_mean_efrac', 'p_mean_ndof', 'p_mean_pixhits', 'p_mean_scthits', 'p_mean_sigmad0', 'p_mean_trthits', 'p_mean_vertex', 'p_mean_z0', 'p_nTracks', 'p_ndof', 'p_numberOfSCTHits', 'p_phi', 'p_pt_track', 'p_qd0Sig', 'p_sct_weight_charge', 'p_sigmad0', 'p_tracks', 'p_truth_eta', 'p_truth_phi', 'p_truth_pt', 'p_weta2', 'tile_barrel_Lr1', 'tile_barrel_Lr2', 'tile_barrel_Lr3', 'tracks', 'true_m']\n"
     ]
    }
   ],
   "source": [
    "f = h5.File('./el_data.h5', 'r') ## gives group\n",
    "print('\\033[1;35m Key name:\\033[1;m', list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['correctedAverageMu', 'em_barrel_Lr0', 'em_barrel_Lr1', 'em_barrel_Lr1_fine', 'em_barrel_Lr2', 'em_barrel_Lr3', 'eventNumber', 'mcChannelNumber', 'p_ECIDSResult', 'p_Eratio', 'p_LHLoose', 'p_LHMedium', 'p_LHTight', 'p_LHValue', 'p_Reta', 'p_Rhad', 'p_Rphi', 'p_TRTPID', 'p_TruthOrigin', 'p_TruthType', 'p_charge', 'p_chi2', 'p_d0', 'p_d0Sig', 'p_dPOverP', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_e', 'p_et_calo', 'p_eta', 'p_f1', 'p_f3', 'p_firstEgMotherTruthOrigin', 'p_firstEgMotherTruthType', 'p_iffTruth', 'p_mean_charge', 'p_mean_chi2', 'p_mean_d0', 'p_mean_deta', 'p_mean_dphi', 'p_mean_efrac', 'p_mean_ndof', 'p_mean_pixhits', 'p_mean_scthits', 'p_mean_sigmad0', 'p_mean_trthits', 'p_mean_vertex', 'p_mean_z0', 'p_nTracks', 'p_ndof', 'p_numberOfSCTHits', 'p_phi', 'p_pt_track', 'p_qd0Sig', 'p_sct_weight_charge', 'p_sigmad0', 'p_tracks', 'p_truth_eta', 'p_truth_phi', 'p_truth_pt', 'p_weta2', 'tile_barrel_Lr1', 'tile_barrel_Lr2', 'tile_barrel_Lr3', 'tracks', 'true_m']\n"
     ]
    }
   ],
   "source": [
    "file_name = h5.File('./el_data.h5', 'r') ## gives group\n",
    "keys = list(file_name.keys())\n",
    "print(keys)\n",
    "#print(list(file_name[keys[0]]))\n",
    "#print(list(file_name[keys[1]]))\n",
    "#print(list(file_name[list(file_name.keys())[0]])) ## or\n",
    "file_name.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_datasets(hdf_file):\n",
    "\n",
    "    def h5_dataset_iterator(g, prefix=''):\n",
    "        for key in g.keys():\n",
    "            item = g[key]\n",
    "            path = f'{prefix}/{key}'\n",
    "            if isinstance(item, h5.Dataset): ## test for dataset\n",
    "                yield (path, item)\n",
    "            elif isinstance(item, h5.Group): ## test for group (go down)\n",
    "                yield from h5_dataset_iterator(item, path)\n",
    "\n",
    "    with h5.File(hdf_file, 'r') as f:\n",
    "        for path, _ in h5_dataset_iterator(f):\n",
    "            yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr0\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr1\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr1_fine\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 56, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr2\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /em_barrel_Lr3\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /eventNumber\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /mcChannelNumber\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_ECIDSResult\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Eratio\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHLoose\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHMedium\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHTight\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_LHValue\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Reta\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Rhad\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_Rphi\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_TRTPID\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_TruthOrigin\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_TruthType\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_charge\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_chi2\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_d0\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_d0Sig\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_dPOverP\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_deltaEta1\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_deltaPhiRescaled2\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_e\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_et_calo\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_eta\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_f1\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_f3\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_firstEgMotherTruthOrigin\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_firstEgMotherTruthType\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_iffTruth\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_charge\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_chi2\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_d0\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_deta\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_dphi\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_efrac\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_ndof\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_pixhits\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_scthits\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_sigmad0\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_trthits\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_vertex\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_mean_z0\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_nTracks\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_ndof\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_numberOfSCTHits\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m int32\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_phi\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_pt_track\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_qd0Sig\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_sct_weight_charge\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_sigmad0\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_tracks\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 20, 13)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_truth_eta\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_truth_phi\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_truth_pt\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /p_weta2\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tile_barrel_Lr1\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tile_barrel_Lr2\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tile_barrel_Lr3\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 7, 11)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /tracks\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920, 50, 5)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n",
      "\u001b[1;35m Path:\u001b[1;m /true_m\n",
      "\u001b[1;36m Shape:\u001b[1;m (19920,)\n",
      "\u001b[1;33m Data type:\u001b[1;m float16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with h5.File('./el_data.h5', 'r') as f:\n",
    "    for dset in traverse_datasets('./el_data.h5'):\n",
    "        \n",
    "        print('\\033[1;35m Path:\\033[1;m', dset)\n",
    "        \n",
    "        print('\\033[1;36m Shape:\\033[1;m', f[dset].shape)\n",
    "        \n",
    "        print('\\033[1;33m Data type:\\033[1;m', f[dset].dtype)\n",
    "        \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(data_file, batch_size, all_features, images, upscale=False, denormalize=False, index=0):\n",
    "    data = h5.File(data_file, 'r')\n",
    "    idx_1, idx_2 = index*batch_size, (index+1)*batch_size\n",
    "    sample_dict  = dict([key, data[key][idx_1:idx_2]] for key in all_features)\n",
    "    if images != [] and denormalize:\n",
    "        energy = sample_dict['p_e']\n",
    "        for key in images: sample_dict[key] = sample_dict[key] * energy[:, np.newaxis, np.newaxis]\n",
    "        sample_dict['tracks'][:,:,0] = sample_dict['tracks'][:,:,0] * energy[:, np.newaxis]\n",
    "    if images != [] and upscale:\n",
    "        for i in images: sample_dict[i] = resize_images(np.float32(sample_dict[i]), target_shape=(56,11))\n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images    = ['em_barrel_Lr0',  'em_barrel_Lr1', 'em_barrel_Lr2', 'em_barrel_Lr3',\n",
    "             'tile_barrel_Lr1', 'tile_barrel_Lr2', 'tile_barrel_Lr3']\n",
    "#images    = ['em_barrel_Lr1_fine']\n",
    "tracks    = ['tracks' ]\n",
    "scalars   = ['p_Eratio', 'p_Reta', 'p_Rhad', 'p_Rphi', 'p_TRTPID', 'p_d0', 'p_d0Sig', 'p_dPOverP',\n",
    "             'p_deltaPhiRescaled2', 'p_deltaEta1', 'p_f1', 'p_f3', 'p_numberOfSCTHits', 'p_weta2']\n",
    "others    = ['p_TruthType', 'p_iffTruth', 'p_LHTight', 'p_LHMedium', 'p_LHLoose', 'p_e']\n",
    "#train_features = {'images':images, 'tracks':tracks, 'scalars':scalars}\n",
    "train_features = {'images':images, 'tracks':[], 'scalars':[]}\n",
    "all_features   = np.sum(list(train_features.values())) + others\n",
    "if train_features['images'] == []: args.n_type = 'FCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12790923264"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(device=None).total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './el_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_e = 1000000\n",
    "n_e = 19920\n",
    "xtrain_data = make_sample(data_file, n_e, all_features, train_features['images'], upscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [ np.expand_dims(np.float32(xtrain_data[key]),axis = 1)  for key in np.sum(list(train_features.values()))]\n",
    "#train_data = [np.float32(train_data[key])[:,np.newaxis,:,:]  for key in np.sum(list(train_features.values()))]\n",
    "#train_data = [np.float32(train_data[key]) for key in np.sum(list(train_features.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19920, 1, 7, 11)\n",
      "(19920, 1, 7, 11)\n",
      "(19920, 1, 7, 11)\n",
      "(19920, 1, 7, 11)\n",
      "(19920, 1, 7, 11)\n",
      "(19920, 1, 7, 11)\n",
      "(19920, 1, 7, 11)\n"
     ]
    }
   ],
   "source": [
    "for element in train_data:\n",
    "    print(element.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19920, 7, 7, 11)\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate(train_data, axis=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(data, n_classes):\n",
    "    if   n_classes == 2:\n",
    "        labels = np.where(np.logical_or(data['p_TruthType']==2, data['p_TruthType']==4), 0, 1)\n",
    "    elif n_classes == 5:\n",
    "        truth  = data['p_iffTruth']\n",
    "        labels = np.where(truth==2, 0, 4     )\n",
    "        labels = np.where(truth==3, 1, labels)\n",
    "        labels = np.where(np.logical_or (truth==1, truth==10), 2, labels)\n",
    "        labels = np.where(np.logical_and(truth>=7, truth<= 9), 3, labels)\n",
    "    elif n_classes == 9:\n",
    "        labels = data['p_iffTruth']\n",
    "        labels = np.where(labels== 9, 4, labels)\n",
    "        labels = np.where(labels==10, 6, labels)\n",
    "    else:\n",
    "        print('\\nCLASSIFIER:', n_classes, 'classes not supported -> exiting program\\n')\n",
    "        sys.exit()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19920,)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "y = make_labels(xtrain_data, n_classes)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x -= np.mean(x, axis=0)\n",
    "x /= np.std(x, axis=0)\n",
    "shuffle_idx = np.random.permutation(x.shape[0])\n",
    "x = x[shuffle_idx]\n",
    "y = y[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 5/6\n",
    "idx = int(train_frac * len(x))\n",
    "x_train, x_test = x[:idx], x[idx:]\n",
    "y_train, y_test = y[:idx], y[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "#num_epochs=20\n",
    "num_epochs=100\n",
    "#num_classes=10\n",
    "nw=1\n",
    "bs1=1000\n",
    "bs2=1000\n",
    "#bs=64\n",
    "#wd=1e-5\n",
    "lr=3e-4\n",
    "#momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_x = torch.stack([torch.Tensor(i) for i in x_train])\n",
    "train_tensor_y = torch.stack([torch.zeros([1])+i for i in y_train])\n",
    "train_tensor_y = train_tensor_y.type(torch.long).squeeze(1)\n",
    "#train_tensor_ycpu = train_tensor_y.to('cpu')\n",
    "#train_tensor_xcpu = train_tensor_x.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m tensor_x type: \u001b[1;m torch.FloatTensor\n",
      "\u001b[1;35m tensor_x dtype: \u001b[1;m torch.float32\n",
      "\u001b[1;36m tensor_x num of dims: \u001b[1;m 4\n",
      "\u001b[1;34m tensor_x Shape:\u001b[1;m torch.Size([16600, 7, 7, 11])\n",
      "\u001b[1;33m tensor_y type: \u001b[1;m torch.LongTensor\n",
      "\u001b[1;35m tensor_y dtype: \u001b[1;m torch.int64\n",
      "\u001b[1;36m tensor_y num of dims: \u001b[1;m 1\n",
      "\u001b[1;34m tensor_y Shape:\u001b[1;m torch.Size([16600])\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;33m tensor_x type: \\033[1;m', train_tensor_x.type())\n",
    "print('\\033[1;35m tensor_x dtype: \\033[1;m', train_tensor_x.dtype)\n",
    "print('\\033[1;36m tensor_x num of dims: \\033[1;m', train_tensor_x.dim())\n",
    "print('\\033[1;34m tensor_x Shape:\\033[1;m', train_tensor_x.shape)\n",
    "print('\\033[1;33m tensor_y type: \\033[1;m', train_tensor_y.type())\n",
    "print('\\033[1;35m tensor_y dtype: \\033[1;m', train_tensor_y.dtype)\n",
    "print('\\033[1;36m tensor_y num of dims: \\033[1;m', train_tensor_y.dim())\n",
    "print('\\033[1;34m tensor_y Shape:\\033[1;m', train_tensor_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor_x = torch.stack([torch.Tensor(i) for i in x_test])\n",
    "test_tensor_y = torch.stack([torch.zeros([1])+i for i in y_test])\n",
    "test_tensor_y = test_tensor_y.type(torch.long).squeeze(1)\n",
    "#test_tensor_ycpu = test_tensor_y.to('cpu')\n",
    "#test_tensor_xcpu = test_tensor_x.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m tensor_x type: \u001b[1;m torch.FloatTensor\n",
      "\u001b[1;35m tensor_x dtype: \u001b[1;m torch.float32\n",
      "\u001b[1;36m tensor_x num of dims: \u001b[1;m 4\n",
      "\u001b[1;34m tensor_x Shape:\u001b[1;m torch.Size([3320, 7, 7, 11])\n",
      "\u001b[1;33m tensor_x type: \u001b[1;m torch.LongTensor\n",
      "\u001b[1;35m tensor_x dtype: \u001b[1;m torch.int64\n",
      "\u001b[1;36m tensor_x num of dims: \u001b[1;m 1\n",
      "\u001b[1;34m tensor_x Shape:\u001b[1;m torch.Size([3320])\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;33m tensor_x type: \\033[1;m', test_tensor_x.type())\n",
    "print('\\033[1;35m tensor_x dtype: \\033[1;m', test_tensor_x.dtype)\n",
    "print('\\033[1;36m tensor_x num of dims: \\033[1;m', test_tensor_x.dim())\n",
    "print('\\033[1;34m tensor_x Shape:\\033[1;m', test_tensor_x.shape)\n",
    "print('\\033[1;33m tensor_x type: \\033[1;m', test_tensor_y.type())\n",
    "print('\\033[1;35m tensor_x dtype: \\033[1;m', test_tensor_y.dtype)\n",
    "print('\\033[1;36m tensor_x num of dims: \\033[1;m', test_tensor_y.dim())\n",
    "print('\\033[1;34m tensor_x Shape:\\033[1;m', test_tensor_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "val_transformer = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_x.transform=train_transformer\n",
    "test_tensor_x.transform=val_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_tensor_x, train_tensor_y) \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs1, num_workers=nw, shuffle=True) \n",
    "valid_dataset = torch.utils.data.TensorDataset(test_tensor_x, test_tensor_y) \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=bs2, num_workers=nw, shuffle=False) \n",
    "\n",
    "#Burda shuffle true false vs gibi seçenekleri de alabiliriz\n",
    "#Number of workers'ı 1'den farklı alınca sorun çıkıyor çözemedim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0002), tensor(1.0101))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_tensor_x), num_workers=1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "valid_loader = DeviceDataLoader(valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(net, valid_loader):\n",
    "    net.eval()\n",
    "    outputs = [net.validation_step(batch) for batch in valid_loader]\n",
    "    return net.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, net, train_loader, valid_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(net.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        net.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = net.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation net\n",
    "        result = evaluate(net, valid_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        net.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(7, 32, kernel_size=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(1), \n",
    "            nn.Linear(13*17*16, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(7, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(32, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Flatten()\n",
       "    (13): Linear(in_features=3536, out_features=100, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CnnModel()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = to_device(CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6759819388389587, 'val_acc': 0.6339687705039978}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(net, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "import optim ######run the optim.py file\n",
    "\n",
    "\n",
    "######################################\n",
    "#ap('-m', help='mnistfc | mnistconv | allcnn', type=str, default='mnistconv')\n",
    "#ap('-b',help='Batch size', type=int, default=128)\n",
    "#ap('-B', help='Max epochs', type=int, default=100)\n",
    "#ap('--lr', help='Learning rate', type=float, default=0.1)\n",
    "#ap('--l2', help='L2', type=float, default=0.0)\n",
    "#ap('-L', help='Langevin iterations', type=int, default=0)\n",
    "#ap('--gamma', help='gamma', type=float, default=1e-4)\n",
    "#ap('--scoping', help='scoping', type=float, default=1e-3)\n",
    "#ap('--noise', help='SGLD noise', type=float, default=1e-4)\n",
    "#ap('-g', help='GPU idx.', type=int, default=0)\n",
    "#ap('-s', help='seed', type=int, default=42)\n",
    "\n",
    "###optimizerdaki parametreler\n",
    "#optimizer = optim.EntropySGD(model.parameters(),\n",
    "        #config = dict(lr=opt['lr'], momentum=0.9, nesterov=True, weight_decay=opt['l2'],\n",
    "        #L=opt['L'], eps=opt['noise'], g0=opt['gamma'], g1=opt['scoping']))\n",
    "\n",
    "#### optim.py filedan EnntropySGDyi cagiriyorsunuz. Ben default parametreleri atadim\n",
    "### asagida. Parametrelerin taninimi yukarida mevcut. \n",
    "#Siz dilediginiz gibi degistirebilirsiniz.\n",
    "optimizer =  optim.EntropySGD(net.parameters(),\n",
    "        config = dict(lr=0.0003, momentum=0.9, nesterov=True, weight_decay=1e-3,\n",
    "        L=20, eps=1e-4, g0=0.03, g1=1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "  \n",
    "#from __future__ import print_function\n",
    "\n",
    "exec('from __future__ import print_function')\n",
    "import argparse, math, random\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from timeit import default_timer as timer\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import models, loader, optim\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "import torch_utils\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "print(len(train_loader)/27)\n",
    "\n",
    "def train(e):\n",
    "    net.train()\n",
    "\n",
    "    fs, top1 = AverageMeter(),  AverageMeter()\n",
    "    ts = timer()\n",
    "\n",
    "    bsz = 5000\n",
    "    maxb = 10\n",
    "    #maxb = int(math.ceil(len(train_loader)/bsz))\n",
    "    #print(len(trainloader))\n",
    "   \n",
    "  \n",
    "\n",
    "    for bi in range(maxb):\n",
    "      #helper() is closure\n",
    "        def helper():\n",
    "            def feval():\n",
    "                x,y = next(iter(train_loader))\n",
    "                if torch.cuda.is_available():\n",
    "                    x,y = x.cuda(), y.cuda()\n",
    "\n",
    "                x, y = Variable(x), Variable(y.squeeze())\n",
    "                bsz = x.size(0)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                yh = net(x)\n",
    "                f = criterion.forward(yh, y)\n",
    "                f.backward()\n",
    "\n",
    "                prec1, = accuracy(yh.data, y.data, topk=(1,))\n",
    "                err = 100.-prec1.item()\n",
    "                return (f.data.item(), err)\n",
    "            return feval\n",
    "      \n",
    "        f, err = optimizer.step(helper(), net, criterion)\n",
    "\n",
    "        fs.update(f, bsz)\n",
    "        top1.update(err, bsz)\n",
    "\n",
    "        if bi % 100 == 0 and bi != 0:\n",
    "            print('[%2d][%4d/%4d] %2.4f %2.2f%%'%(e,bi,maxb, fs.avg, top1.avg))\n",
    "\n",
    "    print('Train: [%2d] %2.4f %2.2f%% [%.2fs]'% (e, fs.avg, top1.avg, timer()-ts))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dropout(cache = None, p=0):\n",
    "    if cache is None:\n",
    "        cache = []\n",
    "        for l in net.modules(): #change net with your module name\n",
    "            if 'Dropout' in str(type(l)):\n",
    "                cache.append(l.p)\n",
    "                l.p = p\n",
    "        return cache\n",
    "    else:\n",
    "        for l in net.modules():#net is my cnn model. change it.\n",
    "            if 'Dropout' in str(type(l)):\n",
    "                assert len(cache) > 0, 'cache is empty'\n",
    "                l.p = cache.pop(0)\n",
    "\n",
    "def dry_feed():\n",
    "    cache = set_dropout()\n",
    "    bsz = 5000\n",
    "   \n",
    "    maxb = int(math.ceil(len(train_loader)/bsz))\n",
    "    for bi in range(maxb):\n",
    "        x,y = next(iter(train_loader))\n",
    "        if torch.cuda.is_available():\n",
    "            x,y = x.cuda(), y.cuda()\n",
    "        x,y =   Variable(x, volatile=True), \\\n",
    "                Variable(y.squeeze(), volatile=True)\n",
    "        yh = net(x)\n",
    "    set_dropout(cache)\n",
    "\n",
    "def val(e, loader):######### change with your  testloader\n",
    "    dry_feed()\n",
    "    net.eval()\n",
    "    bsz = 128\n",
    "    maxb = 10\n",
    "    #maxb = int(math.ceil(len(train_loader)/bsz))\n",
    "\n",
    "    fs, top1 = AverageMeter(), AverageMeter()\n",
    "    for bi in range(maxb):\n",
    "        x,y = next(iter(loader))\n",
    "        bsz = x.size(0)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            x,y = x.cuda(), y.cuda()\n",
    "\n",
    "        x,y =   Variable(x, ), \\\n",
    "                Variable(y.squeeze(), volatile=True)\n",
    "        yh = net(x)\n",
    "\n",
    "        f = criterion.forward(yh, y).item()\n",
    "        prec1, = accuracy(yh.data, y.data, topk=(1,))\n",
    "        err = 100-prec1.item()\n",
    "\n",
    "        fs.update(f, bsz)\n",
    "        top1.update(err, bsz)\n",
    "\n",
    "    print('Test: [%2d] %2.4f %2.4f%%\\n'%(e, fs.avg, top1.avg))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 0] 0.6757 36.63% [50.17s]\n",
      "\n",
      "Test: [ 0] 0.6751 36.5000%\n",
      "\n",
      "\n",
      "Train: [ 1] 0.6761 37.46% [44.35s]\n",
      "\n",
      "Train: [ 2] 0.6745 37.14% [51.98s]\n",
      "\n",
      "Train: [ 3] 0.6727 36.80% [46.08s]\n",
      "\n",
      "Train: [ 4] 0.6713 36.61% [48.13s]\n",
      "\n",
      "Train: [ 5] 0.6695 36.26% [46.28s]\n",
      "\n",
      "Test: [ 5] 0.6694 36.5000%\n",
      "\n",
      "\n",
      "Train: [ 6] 0.6698 36.85% [48.82s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "    train(e)\n",
    "    if e % 5 == 0:\n",
    "        val(e, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
